{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 3: Policy Search\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The player **taking the last object wins**.\n",
    "\n",
    "* Task3.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task3.2: An agent using evolved rules\n",
    "* Task3.3: An agent using minmax\n",
    "* Task3.4: An agent using reinforcement learning\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab3` inside the course repo \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n",
    "## Deadlines ([AoE](https://en.wikipedia.org/wiki/Anywhere_on_Earth))\n",
    "\n",
    "* Sunday, December 4th for Task3.1 and Task3.2\n",
    "* Sunday, December 11th for Task3.3 and Task3.4\n",
    "* Sunday, December 18th for all reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section was provided by Professor Squillero\n",
    "\n",
    "import logging\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from typing import Callable\n",
    "from copy import deepcopy\n",
    "from itertools import accumulate\n",
    "from operator import xor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Namedtuple that contains the instructions for a single move, it is the results of a single call of a \"strategy\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section was provided by Professor Squillero\n",
    "\n",
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Nim class contains all methods and properties to instantiate a Nim game, and the nimming function to handle a ply and modify the board accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section was provided by Professor Squillero\n",
    "\n",
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    @property\n",
    "    def k(self) -> int:\n",
    "        return self._k\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample (and silly) startegies "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random strategy, making random moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section was provided by Professor Squillero\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "def pure_random(state: Nim) -> Nimply:\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple rule-based strategy that improves over the random making the winning move in case the possibiliy arises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section was provided by Professor Squillero\n",
    "\n",
    "def gabriele(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (-m[0], m[1])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for verifying the nim_sum value and a function that analyzes the conditions of the boards and outputs a dictionary with some info, that a strategy-making function may use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nim_sum(state: Nim) -> int:\n",
    "    *_, result = accumulate(state.rows, xor)\n",
    "    return result\n",
    "\n",
    "\n",
    "def cook_status(state: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = [\n",
    "        (r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1) if state.k is None or o <= state.k\n",
    "    ]\n",
    "    cooked[\"active_rows_number\"] = sum(o > 0 for o in state.rows)\n",
    "    cooked[\"shortest_row\"] = min((x for x in enumerate(state.rows) if x[1] > 0), key=lambda y: y[1])[0]\n",
    "    cooked[\"longest_row\"] = max((x for x in enumerate(state.rows)), key=lambda y: y[1])[0]\n",
    "    cooked[\"nim_sum\"] = nim_sum(state)\n",
    "\n",
    "    brute_force = list()\n",
    "    for m in cooked[\"possible_moves\"]:\n",
    "        tmp = deepcopy(state)\n",
    "        tmp.nimming(m)\n",
    "        brute_force.append((m, nim_sum(tmp)))\n",
    "    cooked[\"brute_force\"] = brute_force\n",
    "\n",
    "    return cooked"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal stratgy that relies on nim sum computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section was provided by Professor Squillero\n",
    "\n",
    "def optimal_strategy(state: Nim) -> Nimply:\n",
    "    data = cook_status(state)\n",
    "    return next((bf for bf in data[\"brute_force\"] if bf[1] == 0), random.choice(data[\"brute_force\"]))[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random strategy enclosed in the make strategy method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section was provided by Professor Squillero\n",
    "\n",
    "def make_strategy(genome: dict) -> Callable:\n",
    "    def evolvable(state: Nim) -> Nimply:\n",
    "        data = cook_status(state)\n",
    "\n",
    "        if random.random() < genome[\"p\"]:\n",
    "            ply = Nimply(data[\"shortest_row\"], random.randint(1, state.rows[data[\"shortest_row\"]]))\n",
    "        else:\n",
    "            ply = Nimply(data[\"longest_row\"], random.randint(1, state.rows[data[\"longest_row\"]]))\n",
    "\n",
    "        return ply\n",
    "\n",
    "    return evolvable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate function to compare two strategies one against the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(strategy1: Callable, strategy2: Callable, size=11, num_matches=100) -> float:\n",
    "    players = (strategy1, strategy2)\n",
    "    won = 0\n",
    "\n",
    "    for m in range(num_matches):\n",
    "        nim = Nim(size)\n",
    "        player = 0\n",
    "        while nim:\n",
    "            ply = players[player](nim)\n",
    "            nim.nimming(ply)\n",
    "            player = 1 - player\n",
    "        if player == 1:\n",
    "            won += 1\n",
    "    return won / num_matches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to show visually the steps of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_game(strategy1: Callable, strategy2: Callable, size=10) -> None:\n",
    "    players = (strategy1, strategy2)\n",
    "    won = 0\n",
    "\n",
    "    logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "    nim = Nim(size)\n",
    "    logging.debug(f\"status: Initial board -> {nim}\")\n",
    "    player = 0\n",
    "    while nim:\n",
    "        ply = players[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        logging.debug(f\"status: After player {player} -> {nim}\")\n",
    "        player = 1 - player\n",
    "    winner = 1 - player\n",
    "    logging.info(f\"status: Player {winner} won!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:'gabriele' strategy vs. pure random  -> 0.82\n",
      "DEBUG:root:status: Initial board -> <1 3 5 7 9 11 13 15 17 19>\n",
      "DEBUG:root:status: After player 0 -> <1 1 5 7 9 11 13 15 17 19>\n",
      "DEBUG:root:status: After player 1 -> <1 1 5 7 9 11 13 15 2 19>\n",
      "DEBUG:root:status: After player 0 -> <1 1 5 7 9 11 13 15 2 0>\n",
      "DEBUG:root:status: After player 1 -> <1 1 5 7 9 11 6 15 2 0>\n",
      "DEBUG:root:status: After player 0 -> <1 1 5 7 2 11 6 15 2 0>\n",
      "DEBUG:root:status: After player 1 -> <1 1 3 7 2 11 6 15 2 0>\n",
      "DEBUG:root:status: After player 0 -> <1 1 3 1 2 11 6 15 2 0>\n",
      "DEBUG:root:status: After player 1 -> <1 1 3 1 2 11 6 0 2 0>\n",
      "DEBUG:root:status: After player 0 -> <1 1 3 1 2 4 6 0 2 0>\n",
      "DEBUG:root:status: After player 1 -> <1 1 3 1 2 4 6 0 0 0>\n",
      "DEBUG:root:status: After player 0 -> <1 1 1 1 2 4 6 0 0 0>\n",
      "DEBUG:root:status: After player 1 -> <1 1 1 1 2 4 1 0 0 0>\n",
      "DEBUG:root:status: After player 0 -> <1 1 1 1 2 3 1 0 0 0>\n",
      "DEBUG:root:status: After player 1 -> <1 0 1 1 2 3 1 0 0 0>\n",
      "DEBUG:root:status: After player 0 -> <0 0 1 1 2 3 1 0 0 0>\n",
      "DEBUG:root:status: After player 1 -> <0 0 0 1 2 3 1 0 0 0>\n",
      "DEBUG:root:status: After player 0 -> <0 0 0 0 2 3 1 0 0 0>\n",
      "DEBUG:root:status: After player 1 -> <0 0 0 0 2 2 1 0 0 0>\n",
      "DEBUG:root:status: After player 0 -> <0 0 0 0 2 2 0 0 0 0>\n",
      "DEBUG:root:status: After player 1 -> <0 0 0 0 2 1 0 0 0 0>\n",
      "DEBUG:root:status: After player 0 -> <0 0 0 0 1 1 0 0 0 0>\n",
      "DEBUG:root:status: After player 1 -> <0 0 0 0 0 1 0 0 0 0>\n",
      "DEBUG:root:status: After player 0 -> <0 0 0 0 0 0 0 0 0 0>\n",
      "INFO:root:status: Player 0 won!\n"
     ]
    }
   ],
   "source": [
    "logging.info(f\"'gabriele' strategy vs. pure random  -> {evaluate(gabriele, pure_random)}\")\n",
    "show_game(optimal_strategy, optimal_strategy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Agent with hard-coded rules\n",
    "Sub-optimal agent implementing an expert system through hard-coded rules, which aims to consistently defeat the pure-random strategy and the \"gabriele\" strategy, but will probably be consistently defeated by the optimal strategy and nim sum.\n",
    "I changed the terminology because speaking about hard-coded rules the term genome seems out of place, and parameters seems more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_coded(params: dict) -> Callable:\n",
    "    def evolvable(state: Nim) -> Nimply:\n",
    "        data = cook_status(state)\n",
    "\n",
    "        if data[\"active_rows_number\"] > 2: # if there are more than two active rows, empties one row\n",
    "            ply = Nimply(data[\"longest_row\"], 1)\n",
    "        elif data[\"active_rows_number\"] == 2: # if there are two active rows, leaves one element in the longest row\n",
    "            ply = Nimply(data[\"longest_row\"], state.rows[data[\"longest_row\"]]-1 if state.rows[data[\"longest_row\"]]>=2 else state.rows[data[\"longest_row\"]])\n",
    "        else:\n",
    "            ply = Nimply(data[\"longest_row\"], state.rows[data[\"longest_row\"]])\n",
    "        return ply\n",
    "\n",
    "    return evolvable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: Hard coded strategy vs. 'gabriele' -> 1.0\n"
     ]
    }
   ],
   "source": [
    "params_empty = dict()\n",
    "logging.info(f\" Hard coded strategy vs. 'gabriele' -> {evaluate(hard_coded(params_empty), gabriele)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Agent implementing nim sum, or Optimal Strategy\n",
    "Sub-optimal agent implementing an expert system through hard-coded rules, which aims to consistently defeat the pure-random strategy and the \"gabriele\" strategy, but will probably be consistently defeated by the optimal strategy and nim sum.\n",
    "I changed the terminology because speaking about hard-coded rules the term genome seems out of place, and parameters seems more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: Optimal strategy w/ nim sum vs. Hard Coded -> 1.0\n",
      "INFO:root: Optimal strategy w/ nim sum vs. previous optimal strategy -> 1.0\n",
      "INFO:root: Previous optimal strategy vs. Optimal strategy w/ nim sum -> 1.0\n"
     ]
    }
   ],
   "source": [
    "def nim_sum_strategy(state: Nim) -> Nimply:\n",
    "    data = cook_status(state)\n",
    "    params_empty = dict()\n",
    "    nim_sum_positive_moves = [move for move in data[\"brute_force\"] if move[1] == 0]\n",
    "    if len(nim_sum_positive_moves) > 0:\n",
    "        ply = random.choice(nim_sum_positive_moves)[0]\n",
    "    else:\n",
    "        if data[\"active_rows_number\"] > 2: # if there are more than two active rows, empties one row\n",
    "            ply = Nimply(data[\"longest_row\"], 1)\n",
    "        elif data[\"active_rows_number\"] == 2: # if there are two active rows, leaves one element in the longest row\n",
    "            ply = Nimply(data[\"longest_row\"], state.rows[data[\"longest_row\"]]-1 if state.rows[data[\"longest_row\"]]>=2 else state.rows[data[\"longest_row\"]])\n",
    "        else:\n",
    "            ply = Nimply(data[\"longest_row\"], state.rows[data[\"longest_row\"]])\n",
    "    return ply\n",
    "\n",
    "params_empty = dict()\n",
    "logging.info(f\" Optimal strategy w/ nim sum vs. Hard Coded -> {evaluate(nim_sum_strategy, hard_coded(params_empty))}\")\n",
    "logging.info(f\" Optimal strategy w/ nim sum vs. previous optimal strategy -> {evaluate(nim_sum_strategy, optimal_strategy)}\")\n",
    "logging.info(f\" Previous optimal strategy vs. Optimal strategy w/ nim sum -> {evaluate(optimal_strategy, nim_sum_strategy)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Agent with evolved rules\n",
    "\n",
    "Sub-optimal agent implementing evolving rules through the implementation of a genetic algorithm.\n",
    "This first strategy is a \"placeholder\" as it mimics our hard-coded expert system but sometimes proposing straight-up \"suicidal\" moves.\n",
    "Especially in genome[2] we expect the value 1 to dominate.\n",
    "Using this system we'll set up the elements of our GA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolving_strategy(genome: list) -> Callable:\n",
    "    def evolvable(state: Nim) -> Nimply:\n",
    "        data = cook_status(state)\n",
    "        \n",
    "        # early game policy\n",
    "        if genome[0] == 0 & data[\"active_rows_number\"] > 2:\n",
    "            ply = Nimply(data[\"longest_row\"], 1)\n",
    "        elif genome[0] == 1 & data[\"active_rows_number\"] > 2:\n",
    "            ply = Nimply(data[\"longest_row\"], state.rows[data[\"longest_row\"]])\n",
    "        elif genome[0] == 2 & data[\"active_rows_number\"] > 2:\n",
    "            ply = Nimply(data[\"shortest_row\"], state.rows[data[\"shortest_row\"]])\n",
    "\n",
    "        # \"mid\" game policy\n",
    "        if genome[1] == 0 & data[\"active_rows_number\"] == 2:\n",
    "            ply = Nimply(data[\"longest_row\"], 1)\n",
    "        elif genome[1] == 1 & data[\"active_rows_number\"] == 2:\n",
    "            ply = Nimply(data[\"longest_row\"], state.rows[data[\"longest_row\"]])\n",
    "        elif genome[1] == 2 & data[\"active_rows_number\"] == 2:\n",
    "            ply = Nimply(data[\"shortest_row\"], state.rows[data[\"shortest_row\"]]-1 if state.rows[data[\"shortest_row\"]]>=2 else 1)\n",
    "\n",
    "        # end game policy\n",
    "        if genome[2] == 0 & data[\"active_rows_number\"] == 1:\n",
    "            ply = Nimply(data[\"longest_row\"], 1)\n",
    "        elif genome[2] == 1 & data[\"active_rows_number\"] == 1:\n",
    "            ply = Nimply(data[\"longest_row\"], state.rows[data[\"longest_row\"]])\n",
    "        else:\n",
    "            ply = Nimply(data[\"longest_row\"], state.rows[data[\"longest_row\"]]-1 if state.rows[data[\"longest_row\"]]>=2 else 1)\n",
    "        \n",
    "        return ply\n",
    "    \n",
    "    return evolvable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament(population, tournament_size=2):\n",
    "    return max(random.choices(population, k=tournament_size), key=lambda i: i[1])\n",
    "\n",
    "def crossover(gene1, gene2, genome_size):\n",
    "    cut = random.randint(0, genome_size-1) #i have 3 rules\n",
    "    return gene1[0][:cut] + gene2[0][cut:]\n",
    "\n",
    "def mutation(gene, genome_size):\n",
    "    point = random.randint(0, genome_size)\n",
    "    return gene[:point] + [random.randint(0, 2)] + gene[point + 1 :]\n",
    "\n",
    "def fitness1(genome): # pure random fitness\n",
    "    return evaluate(evolving_strategy(genome), pure_random, num_matches=50)\n",
    "\n",
    "def fitness2(genome): # gabriele fitness\n",
    "    return evaluate(evolving_strategy(genome), gabriele, num_matches=50)\n",
    "\n",
    "def fitness3(genome): # hard-coded fitness\n",
    "    return evaluate(evolving_strategy(genome), gabriele, num_matches=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm(genome: list):\n",
    "    \n",
    "    # genetic algorithm parameters\n",
    "    generations = 30\n",
    "    population_size = 10\n",
    "    offspring_size = 5\n",
    "    genome_size=len(genome)\n",
    "    probs = [0.3, 0.4, 0.5]\n",
    "    \n",
    "    fitness = fitness1\n",
    "\n",
    "    # checks for plateaus in fitness improvement\n",
    "    plateau_count = 0 \n",
    "    population = [list([i, fitness(i)]) for i in ([random.choice([0,1,2]) for _ in range(len(genome))] for _ in range(population_size))]\n",
    "\n",
    "    # create fitness log\n",
    "    fitness_log = [(0, i[1]) for i in population]\n",
    "    \n",
    "    # evolutionary algorithm\n",
    "    for g in range(generations):\n",
    "        offspring = list()\n",
    "        \n",
    "        for i in range(offspring_size): \n",
    "            #decide the probability of crossover/mutation\n",
    "            \n",
    "            prob=probs[g//10]\n",
    "            if random.random() < prob:\n",
    "                p = tournament(population)\n",
    "                o = mutation(p[0],genome_size)\n",
    "            else:\n",
    "                p1 = tournament(population)\n",
    "                p2 = tournament(population)\n",
    "                o = crossover(p1, p2, genome_size)\n",
    "            f = fitness(o)\n",
    "            fitness_log.append((g + 1, f))\n",
    "            offspring.append(list([o, f]))\n",
    "        population += offspring\n",
    "        population = sorted(population, key=lambda i: i[1], reverse=True)[:population_size]\n",
    "        # check if we have reached a plateau\n",
    "        fitness_step = 0\n",
    "        if max(f[1] for f in fitness_log if f[0] == g + 1) <= max(f[1] for f in fitness_log if f[0] == g): plateau_count += 1\n",
    "        else: plateau_count = 0\n",
    "        if plateau_count == 20 & fitness_step==0:\n",
    "            fitness = fitness2\n",
    "            fitness_step += 1\n",
    "        elif plateau_count == 20 & fitness_step == 1:\n",
    "            fitness = fitness3\n",
    "            fitness_step += 1\n",
    "        elif plateau_count == 20 & fitness_step == 2:\n",
    "            break\n",
    "    logging.info(f\"The best individual is: {population[0]}\")\n",
    "    return population[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:The best individual is: [[0, 0, 2], 1.0]\n",
      "INFO:root:Final genome: [0, 0, 2]\n",
      "INFO:root:Evolving strategy vs. pure random --> 0.56\n",
      "INFO:root:Evolving strategy vs. gabriele --> 1.0\n",
      "INFO:root:Evolving strategy vs. hard coded --> 0.0\n"
     ]
    }
   ],
   "source": [
    "genome = [0, 0, 0]\n",
    "\n",
    "genome = genetic_algorithm(genome)\n",
    "logging.info(f\"Final genome: {genome}\")\n",
    "logging.info(f\"Evolving strategy vs. pure random --> {evaluate(evolving_strategy(genome), pure_random)}\")\n",
    "logging.info(f\"Evolving strategy vs. gabriele --> {evaluate(evolving_strategy(genome), gabriele)}\")\n",
    "logging.info(f\"Evolving strategy vs. hard coded --> {evaluate(evolving_strategy(genome), hard_coded(dict()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evolving strategy vs. pure random --> 0.5\n",
      "INFO:root:Evolving strategy vs. gabriele --> 1.0\n",
      "INFO:root:Evolving strategy vs. hard coded --> 0.0\n",
      "INFO:root:Evolving strategy vs. Nim sum --> 0.0\n"
     ]
    }
   ],
   "source": [
    "logging.info(f\"Evolving strategy vs. pure random --> {evaluate(evolving_strategy(genome), pure_random)}\")\n",
    "logging.info(f\"Evolving strategy vs. gabriele --> {evaluate(evolving_strategy(genome), gabriele)}\")\n",
    "logging.info(f\"Evolving strategy vs. hard coded --> {evaluate(evolving_strategy(genome), hard_coded(dict()))}\")\n",
    "logging.info(f\"Evolving strategy vs. Nim sum --> {evaluate(evolving_strategy(genome), nim_sum_strategy)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Agent implementing min-max\n",
    "Sub-optimal agent implementing evolving rules through the implementation of a genetic algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(state: Nim, is_maximizing, depth=0, bound=5):\n",
    "\n",
    "    def evaluate_minmax(state: Nim, is_maximizing):\n",
    "        if sum(o>0 for o in state.rows) == 0 or depth>bound:\n",
    "            return -1 if is_maximizing else 1\n",
    "        \n",
    "    if (score := evaluate_minmax(state, is_maximizing)) is not None:\n",
    "        return score\n",
    "    \n",
    "    return (max if is_maximizing else min)(\n",
    "        minmax(new_state, is_maximizing=not is_maximizing, depth=depth+1)\n",
    "        for new_state in possible_new_states(state)\n",
    "    )\n",
    "\n",
    "def extract_move(state1: Nim, state2: Nim) -> Nimply:\n",
    "    for index, row in enumerate(state2.rows):\n",
    "        if state1.rows[index] != state2.rows[index]:\n",
    "            return Nimply(index, state2.rows[index] - state1.rows[index])\n",
    "\n",
    "def possible_new_states(state: Nim):\n",
    "    data=cook_status(state)\n",
    "    new_states = list()\n",
    "    for move in data[\"possible_moves\"]:\n",
    "        tmp=deepcopy(state)\n",
    "        tmp.nimming(move)\n",
    "        new_states.append(tmp)                    \n",
    "    return new_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_strategy(state: Nim) -> Nimply:\n",
    "    tmp=deepcopy(state)\n",
    "    for new_state in possible_new_states(state):\n",
    "        score = minmax(new_state, is_maximizing=False)\n",
    "        \n",
    "        if score > 0:\n",
    "            break \n",
    "        \n",
    "    return extract_move(new_state,tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:min-max strategy vs. hard coded strategy --> 1.0\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "logging.info(f\"min-max strategy vs. hard coded strategy --> {evaluate(minmax_strategy, hard_coded(params_empty),  4, 5)}\")\n",
    "#show_game(minmax_strategy,  nim_sum_strategy, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_alpha_beta(state: Nim, is_maximizing, depth=0, bound=5, alpha=-1, beta=1):\n",
    "\n",
    "    def evaluate_minmax(state: Nim, is_maximizing):\n",
    "        if sum(o>0 for o in state.rows) == 0 or depth>bound:\n",
    "            return -1 if is_maximizing else 1\n",
    "        \n",
    "    if (score := evaluate_minmax(state, is_maximizing)) is not None:\n",
    "        return score\n",
    "    \n",
    "    scores = []\n",
    "    for new_state in possible_new_states(state):\n",
    "        score = minmax(new_state, is_maximizing=not is_maximizing, depth=depth+1)\n",
    "        scores.append(score)\n",
    "        if is_maximizing:\n",
    "            alpha = max(alpha, score)\n",
    "        else:\n",
    "            beta = min(beta, score)\n",
    "        if beta <= alpha:\n",
    "            break\n",
    "    \n",
    "    return max(scores) if is_maximizing else min(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_ab_strategy(state: Nim) -> Nimply:\n",
    "    tmp=deepcopy(state)\n",
    "    for new_state in possible_new_states(state):\n",
    "        score = minmax_alpha_beta(new_state, is_maximizing=False)\n",
    "        \n",
    "        if score > 0:\n",
    "            break \n",
    "        \n",
    "    return extract_move(new_state,tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:min-max strategy vs. hard coded strategy --> 1.0\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "logging.info(f\"min-max strategy vs. hard coded strategy --> {evaluate(minmax_ab_strategy, hard_coded(params_empty), 4, 10)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Agent implementing reinforcement learning techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "global Q, prevState, prevAction\n",
    "\n",
    "Q = {}\n",
    "#prevState = prevAction = None\n",
    "\n",
    "def q_learning(state: Nim, learn=False, alpha = 0.1, gamma = 1, epsilon=0.05) -> Nimply:\n",
    "\n",
    "    #Q is a function f: State x Action -> R and is internally represented as a Map.\n",
    "\n",
    "    #Alpha is the learning rate and determines to what extent the newly acquired \n",
    "    #information will override the old information\n",
    "\n",
    "    #Gamma is the discount rate and determines the importance of future rewards\n",
    "\n",
    "    #Epsilon serves as the exploration rate and determines the probability \n",
    "    #that the agent, in the learning process, will randomly select an action\n",
    "\n",
    "    WIN_REWARD, LOSS_REWARD = 1.0, -1.0\n",
    "\n",
    "    data = cook_status(state) \n",
    "\n",
    "    #If a given state is not in our hashmap, we will add all possible state,\n",
    "    #action pair and initialize the values by randomly sampling from the uniform(0,1)\n",
    "    #(so we can avoid having two actions which attain the maximum Q-value)\n",
    "    def makeKey(state):\n",
    "        possActions = [Nimply(elem[0], elem[1]) for elem in data[\"possible_moves\"]]\n",
    "        someAction = possActions[0]\n",
    "\n",
    "        if (state.rows, someAction) not in Q:\n",
    "            for i in possActions:\n",
    "                if (state.rows, i) not in Q:\n",
    "                    Q[(state.rows, i)] = np.random.uniform(0.0,0.01)\n",
    "    \n",
    "    def choose_ply(state):\n",
    "        makeKey(state)\n",
    "        possActions = [Nimply(elem[0], elem[1]) for elem in data[\"possible_moves\"]]\n",
    "        if np.random.random() > epsilon:\n",
    "            #Returns the action associated with the max Q value\n",
    "            #global Q\n",
    "        \n",
    "            qVal = [Q[(state.rows, a)] for a in possActions]\n",
    "            return possActions[np.argmax(qVal)]\n",
    "        else:\n",
    "            #Selects the action at random \n",
    "            return random.choice(possActions)\n",
    "        \n",
    "    def peek(state, ply):\n",
    "        tmp = deepcopy(state)\n",
    "        tmp.nimming(ply)\n",
    "         \n",
    "        return tmp\n",
    "    \n",
    "    #Updates the Q-table as specified by the standard Q-learning algorithm\n",
    "    def updateQ(state):\n",
    "        makeKey(state)\n",
    "        currAction = choose_ply(state)\n",
    "            \n",
    "        next_state = peek(state, currAction)\n",
    "        if  sum(o > 0 for o in next_state.rows)==1:\n",
    "            reward = LOSS_REWARD\n",
    "            Q[(state.rows, currAction)] += \\\n",
    "                alpha * reward - \\\n",
    "                Q[(state.rows, currAction)]\n",
    "        elif sum(o > 0 for o in next_state.rows)>1:\n",
    "            reward = 0.03\n",
    "            future_data = cook_status(next_state)     \n",
    "            maxQ = max([Q[(state.rows, a)] for a in future_data[\"possible_moves\"]])\n",
    "            Q[(state.rows, currAction)] += \\\n",
    "                alpha * (reward + (gamma * maxQ) - \\\n",
    "                Q[(state.rows, currAction)])\n",
    "        elif sum(o > 0 for o in next_state.rows)==0:\n",
    "            reward = WIN_REWARD\n",
    "            Q[(state.rows, currAction)] += \\\n",
    "                alpha * reward - \\\n",
    "                Q[(state.rows, currAction)]\n",
    "\n",
    "                \n",
    "        return currAction\n",
    "\n",
    "    move = choose_ply(state)\n",
    "    if learn:\n",
    "        move = updateQ(state)\n",
    "        \n",
    "    return move\n",
    "\n",
    "def learn(q_learning: Callable, epochs=30, size=5):\n",
    "    players = (q_learning, pure_random)\n",
    "    learning_log = list()\n",
    "    \n",
    "    \n",
    "    for e in tqdm(range(epochs)):\n",
    "        #if e > epochs/3:\n",
    "        #    players = (q_learning, nim_sum_strategy)\n",
    "        won = 0\n",
    "        num_matches = 4000\n",
    "        for m in range(num_matches):\n",
    "            nim = Nim(size)\n",
    "            player = 0\n",
    "            while nim:\n",
    "                ply = players[player](nim) if player==1 else players[player](nim, True)\n",
    "                nim.nimming(ply)\n",
    "                player = 1 - player\n",
    "            if player == 1:\n",
    "                won += 1\n",
    "        \n",
    "        learning_log.append(won/num_matches*100)\n",
    "\n",
    "    return learning_log\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:q-learning strategy vs. pure random strategy --> 0.506\n",
      "INFO:root:q-learning strategy  vs. hard coded strategy --> 0.086\n",
      "INFO:root:q-learning strategy  vs. nim sum strategy strategy --> 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#learning_log = learn(q_learning)\n",
    "\n",
    "\n",
    "plt.plot(range(len(learning_log)),learning_log)\n",
    "plt.title(\"Nim - Reinforcement Learning Training log\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Win '%' over 1000 games\")\n",
    "\n",
    "logging.info(f\"q-learning strategy vs. pure random strategy --> {evaluate(q_learning, pure_random, 5, 1000)}\")\n",
    "logging.info(f\"q-learning strategy  vs. hard coded strategy --> {evaluate(q_learning, hard_coded(params=params_empty), 5, 1000)}\")\n",
    "logging.info(f\"q-learning strategy  vs. nim sum strategy strategy --> {evaluate(q_learning, nim_sum_strategy, 5, 1000)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
